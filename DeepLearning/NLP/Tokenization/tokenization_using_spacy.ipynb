{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "\n",
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tony gave two $ to Peter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0 = doc[0]\n",
    "token0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony ==> index:  0 is_alpha:  True is_puct:  False like_num:  False is_currency:  False\n",
      "gave ==> index:  1 is_alpha:  True is_puct:  False like_num:  False is_currency:  False\n",
      "two ==> index:  2 is_alpha:  True is_puct:  False like_num:  True is_currency:  False\n",
      "$ ==> index:  3 is_alpha:  False is_puct:  False like_num:  False is_currency:  True\n",
      "to ==> index:  4 is_alpha:  True is_puct:  False like_num:  False is_currency:  False\n",
      "Peter ==> index:  5 is_alpha:  True is_puct:  False like_num:  False is_currency:  False\n",
      ". ==> index:  6 is_alpha:  False is_puct:  True like_num:  False is_currency:  False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, '==>',\n",
    "          'index: ',token.i,\n",
    "          'is_alpha: ',token.is_alpha,\n",
    "          'is_puct: ',token.is_punct,\n",
    "          'like_num: ',token.like_num,\n",
    "          'is_currency: ',token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['School: Nepal public Academy\\n',\n",
       " '\\n',\n",
       " 'Name                           Date                 email\\n',\n",
       " 'Hari sah                17-02-2002           smartharry499@gmail.com\\n',\n",
       " 'Rupesh Sah              8-03-2002            sahrupesh588@gmail.com\\n',\n",
       " 'Omi Sah                  3-2-2002            shaomi@gmail.com\\n',\n",
       " 'Hulk                     23-12-2002           sahrahul4555@gmail.com']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('text.txt') as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'School: Nepal public Academy\\n \\n Name                           Date                 email\\n Hari sah                17-02-2002           smartharry499@gmail.com\\n Rupesh Sah              8-03-2002            sahrupesh588@gmail.com\\n Omi Sah                  3-2-2002            shaomi@gmail.com\\n Hulk                     23-12-2002           sahrahul4555@gmail.com'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[smartharry499@gmail.com,\n",
       " sahrupesh588@gmail.com,\n",
       " shaomi@gmail.com,\n",
       " sahrahul4555@gmail.com]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "email = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        email.append(token)\n",
    "\n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "मेरो\n",
      "नम\n",
      "हरि\n",
      "नरयन\n",
      "सह\n",
      "हो\n",
      "मेरो\n",
      "घर\n",
      "कल्यन्पुर\n",
      "हो\n",
      "मेरो\n",
      "देश\n",
      "को\n",
      "नम\n",
      "नेपल\n",
      "हो\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('ne')\n",
    "\n",
    "doc = nlp(\" मेरो नम हरि नरयन सह हो मेरो घर कल्यन्पुर हो मेरो देश को नम नेपल हो\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('gimme double cheese extra large healthy pizza')\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding special case\n",
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case('gimme',[\n",
    "    {ORTH:'gim'},\n",
    "    {ORTH:'me'}])\n",
    "doc = nlp('gimme double cheese extra large healthy pizza')\n",
    "\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Look for data to hellp you address the question. Goverments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and https://www.science.gov/, and in the United Kingdom , https://data.gov.uk/ .\n",
    "Two of my favorite data seta are the General Social Survey at https://www3.norc.org/gss+website/,and the\n",
    "European Social Survey at http://www.europeansocialsurvey.org\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[http://www.data.gov/,\n",
       " https://www.science.gov/,\n",
       " https://data.gov.uk/,\n",
       " https://www3.norc.org/gss+website/,and,\n",
       " http://www.europeansocialsurvey.org]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "email = [token  for token in doc if token.like_url]\n",
    "#for token in doc:\n",
    "   # if token.like_url:\n",
    "    #    email.append(token)\n",
    "\n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[$, 500, $]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp( \" Tony gave three $ to Peter, Bruce gave 500 $ to Steve\")\n",
    "\n",
    "money = [token for token in doc if token.is_currency | token.like_num]\n",
    "money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three $\n",
      "500 $\n"
     ]
    }
   ],
   "source": [
    "doc = nlp( \" Tony gave three $ to Peter, Bruce gave 500 $ to Steve\")\n",
    "\n",
    "money =[]\n",
    "for token in doc:\n",
    "    #index = token.i\n",
    "    if token.is_currency:\n",
    "        print(doc[token.i-1],token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
